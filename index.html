<!DOCTYPE html>
<html>
<head>
<title>Agora Web Sample</title>
<link rel="stylesheet" href="stylesheet.css">
<!-- Changed by MarinaF -->
<script src="AgoraRTCSDK-2.2.0.js"></script>
<script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>
<script type="text/javascript" src="https://download.affectiva.com/js/3.2/affdex.js"></script>
</head>

<body class="wrap">
  <section class="header">
      <img class="logo flex" src="./images/logo.png">
      <h1 class="flex">HappyVidChat</h1>
      <h4>Video Chat + Coupons</h4>
  </section>

<div id="div_device" class="panel panel-default">
<div class="select">
<label for="audioSource">Audio source: </label><select id="audioSource"></select>
</div> <br>
<div class="select">
<label for="videoSource">Video source: </label><select id="videoSource"></select>
</div>
</div>

<div id="div_join" class="panel panel-default">
<div class="panel-body">
    <section class="key">
      <h2>Key:</h2> <input id="key" type="text" value="" size="36"></input>
      <button id="join" class="btn btn-primary" onclick="join()">Join</button>
          <section class="seperate">
                <h3>Channel:</h3> <input id="channel" type="text" value="1000" size="4"></input>
                <h3>Host:</h3> <input id="video" type="checkbox" checked></input>
          </section>
  </section>


</div>

    <!--style>
    .video__box{width:910px; margin:0 auto; overflow:hidden;}
    .video__main{ width:810px; height:607px;float:left }
    .video__list{ width:200px; height:607px; float:left;}
    .video__item{ width:200px; height:174px; hei background:url(/img/icon_live.png) center center no-repeat; }
    </style>
    <div class="video__main">
    </div>
    <div class="video__list">
        <div class="video__item"></div>
        <div id="video" class="video__item">
            <div id="agora_local"></div>
        </div>
    </div-->

<div id="video" style="margin:0 auto;">
    <div id="agora_local" style="float:center;width:210px;height:147px;display:inline-block;"></div>
    <div id="reward"></div>
</div>

<section class="button">
      <button id="leave" class="btn btn-primary main" onclick="leave()">Leave</button>
      <button id="publish" class="btn btn-primary main" onclick="publish()">Publish</button>
      <button id="unpublish" class="btn btn-primary" onclick="unpublish()">Unpublish</button>
      <button id="muteAudio" class="btn btn-primary main" onclick="muteAudio()">Mute</button>
      <button id="unmuteAudio" class="btn btn-primary" onclick="unmuteAudio()">Unmute</button>
      <button id="enableVideo" class="btn btn-primary main" onclick="enableVideo()">EnableVideo</button>
      <button id="disableVideo" class="btn btn-primary" onclick="disableVideo()">DisableVideo</button>
</section>
</div>

<!-- remove after testing -->
<div class="col-md-4">
  <div style="height:25em;">
    <strong>EMOTION TRACKING RESULTS</strong>
    <div id="results" style="word-wrap:break-word;"></div>
  </div>
  <div>
    <strong>DETECTOR LOG MSGS</strong>
  </div>
  <div id="logs"></div>
</div>
<!-- remove after testing -->
<script language="javascript">
if(!AgoraRTC.checkSystemRequirements()) {
  alert("browser is no support webRTC");
}
/* select Log type */
// AgoraRTC.Logger.setLogLevel(AgoraRTC.Logger.NONE);
// AgoraRTC.Logger.setLogLevel(AgoraRTC.Logger.ERROR);
// AgoraRTC.Logger.setLogLevel(AgoraRTC.Logger.WARNING);
// AgoraRTC.Logger.setLogLevel(AgoraRTC.Logger.INFO);
// AgoraRTC.Logger.setLogLevel(AgoraRTC.Logger.DEBUG);
/* simulated data to proof setLogLevel() */
AgoraRTC.Logger.error('this is error');
AgoraRTC.Logger.warning('this is warning');
AgoraRTC.Logger.info('this is info');
AgoraRTC.Logger.debug('this is debug');
var client, localStream, camera, microphone;
var audioSelect = document.querySelector('select#audioSource');
var videoSelect = document.querySelector('select#videoSource');

// SDK Needs to create video and canvas nodes in the DOM in order to function
// Here we are adding those nodes a predefined div.
var divRoot = $("#agora_local")[0];
var width = 210;
var height = 147;
var faceMode = affdex.FaceDetectorMode.LARGE_FACES;
//Construct a CameraDetector and specify the image width / height and face detector mode.
var detector = new affdex.CameraDetector(divRoot, width, height, faceMode);
var triggered = false;

//Enable detection of all Expressions, Emotions and Emojis classifiers.
detector.detectAllEmotions();
detector.detectAllExpressions();
detector.detectAllEmojis();
detector.detectAllAppearance();

detector.addEventListener("onInitializeSuccess", function() {
        log('#logs', "The detector reports initialized");
        //Display canvas instead of video feed because we want to draw the feature points on it
        $("#face_video_canvas").css("display", "none");
        $("#face_video").css("display", "none");
      });

function log(node_name, msg) {
  //console.log('yep');
        $(node_name).append("<span>" + msg + "</span><br />");
}

function join() {
  document.getElementById("join").disabled = true;
  document.getElementById("video").disabled = true;
  var channel_key = null;
  console.log("Init AgoraRTC client with vendor key: " + key.value);
  client = AgoraRTC.createClient({mode: 'interop'});
  client.init(key.value, function () {
    console.log("AgoraRTC client initialized");
    client.join(channel_key, channel.value, null, function(uid) {
      console.log("User " + uid + " join channel successfully");
      if (document.getElementById("video").checked) {
        camera = videoSource.value;
        microphone = audioSource.value;
        localStream = AgoraRTC.createStream({streamID: uid, audio: true, cameraId: camera, microphoneId: microphone, video: document.getElementById("video").checked, screen: false});
        //localStream = AgoraRTC.createStream({streamID: uid, audio: false, cameraId: camera, microphoneId: microphone, video: false, screen: true, extensionId: 'minllpmhdgpndnkomcoccfekfegnlikg'});
        if (document.getElementById("video").checked) {
          localStream.setVideoProfile('720p_3');
        }
        // The user has granted access to the camera and mic.
        localStream.on("accessAllowed", function() {
          console.log("accessAllowed");
        });
        // The user has denied access to the camera and mic.
        localStream.on("accessDenied", function() {
          console.log("accessDenied");
        });
        localStream.init(function() {
          console.log("getUserMedia successfully");
          localStream.play('agora_local');
          client.publish(localStream, function (err) {
            console.log("Publish local stream error: " + err);
          });
          client.on('stream-published', function (evt) {
            console.log("Publish local stream successfully");
          });
        }, function (err) {
          console.log("getUserMedia failed", err);
        });

        if (detector && !detector.isRunning) {
          $("#logs").html("");
          detector.start();
          $("#face_video_canvas").css("display", "none");
          $("#face_video").css("display", "none");
        }
        console.log("Face detection started");
      }
    }, function(err) {
      console.log("Join channel failed", err);
    });
  }, function (err) {
    console.log("AgoraRTC client init failed", err);
  });
  channelKey = "";
  client.on('error', function(err) {
    console.log("Got error msg:", err.reason);
    if (err.reason === 'DYNAMIC_KEY_TIMEOUT') {
      client.renewChannelKey(channelKey, function(){
        console.log("Renew channel key successfully");
      }, function(err){
        console.log("Renew channel key failed: ", err);
      });
    }
  });
  client.on('stream-added', function (evt) {
    var stream = evt.stream;
    console.log("New stream added: " + stream.getId());
    console.log("Subscribe ", stream);
    client.subscribe(stream, function (err) {
      console.log("Subscribe stream failed", err);
    });
  });
  client.on('stream-subscribed', function (evt) {
    var stream = evt.stream;
    console.log("Subscribe remote stream successfully: " + stream.getId());
    if ($('div#video #agora_remote'+stream.getId()).length === 0) {
      $('div#video').append('<div id="agora_remote'+stream.getId()+'" style="float:left; width:810px;height:607px;display:inline-block;"></div>');
    }
    stream.play('agora_remote' + stream.getId());
  });
  client.on('stream-removed', function (evt) {
    var stream = evt.stream;
    stream.stop();
    $('#agora_remote' + stream.getId()).remove();
    console.log("Remote stream is removed " + stream.getId());
  });
  client.on('peer-leave', function (evt) {
    var stream = evt.stream;
    if (stream) {
      stream.stop();
      $('#agora_remote' + stream.getId()).remove();
      console.log(evt.uid + " leaved from this channel");
    }
  });
}
function leave() {
  document.getElementById("leave").disabled = true;
  client.leave(function () {
    console.log("Leavel channel successfully");
  }, function (err) {
    console.log("Leave channel failed");
  });
  console.log("Face detection stopped");
  if (detector && detector.isRunning) {
    detector.removeEventListener();
    detector.stop();
  }
}
function publish() {
  document.getElementById("publish").disabled = true;
  document.getElementById("unpublish").disabled = false;
  client.publish(localStream, function (err) {
    console.log("Publish local stream error: " + err);
  });
}
function unpublish() {
  document.getElementById("publish").disabled = false;
  document.getElementById("unpublish").disabled = true;
  client.unpublish(localStream, function (err) {
    console.log("Unpublish local stream failed" + err);
  });
}
function muteAudio()
{
  document.getElementById("unmuteAudio").disabled = false;
  document.getElementById("muteAudio").disabled = true;
  //localStream.disableAudio();
 localStream.disableAudio();
}
function unmuteAudio()
{
  document.getElementById("unmuteAudio").disabled = true;
  document.getElementById("muteAudio").disabled = false;
 localStream.enableAudio();
}
function enableVideo()
{
  document.getElementById("disableVideo").disabled = false;
  document.getElementById("enableVideo").disabled = true;
  localStream.enableVideo();
  if (detector && !detector.isRunning) {
          $("#logs").html("");
          detector.start();
          $("#face_video_canvas").css("display", "none");
          $("#face_video").css("display", "none");
        }
  console.log("Face detection started");

}
function disableVideo()
{
  document.getElementById("disableVideo").disabled = true;
  document.getElementById("enableVideo").disabled = false;
  localStream.disableVideo();

  console.log("Face detection stopped");
  if (detector && detector.isRunning) {
    detector.removeEventListener();
    detector.stop();
  }
}

//Affectiva code

 //Add a callback to notify when camera access is allowed
 detector.addEventListener("onWebcamConnectSuccess", function() {
        log('#logs', "Webcam access allowed");
      });

      //Add a callback to notify when camera access is denied
      detector.addEventListener("onWebcamConnectFailure", function() {
        log('#logs', "webcam denied");
        console.log("Webcam access denied");
      });

      //Add a callback to notify when detector is stopped
      detector.addEventListener("onStopSuccess", function() {
        log('#logs', "The detector reports stopped");
        $("#results").html("");
      });

      //Add a callback to receive the results from processing an image.
      //The faces object contains the list of the faces detected in an image.
      //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
      detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
        $('#results').html("");

        // log('#results', "Timestamp: " + timestamp.toFixed(2));
        // log('#results', "Number of faces found: " + faces.length);
        if (faces.length > 0) {
          log('#results', triggered);
          // log('#results', "Appearance: " + JSON.stringify(faces[0].appearance));
          // log('#results', "Emotions: " + JSON.stringify(faces[0].emotions, function(key, val) {
          //   return val.toFixed ? Number(val.toFixed(0)) : val;
          // }));
          // log('#results', "Expressions: " + JSON.stringify(faces[0].expressions, function(key, val) {
          //   return val.toFixed ? Number(val.toFixed(0)) : val;
          // }));
          // log('#results', "Emoji: " + faces[0].emojis.dominantEmoji);
          // log('#results', "Emotions values: " + faces[0].emotions.joy + " " + faces[0].emotions.engagement);
          // log('#results', typeof faces[0].emotions.joy);
          if (!triggered && faces[0].emotions.joy > 98 && faces[0].emotions.engagement > 98) {
            log('#results', "drop Skittles");
            triggered = true;
            $('#reward').html('<img #skittle src="images/skittles50.png">');
          }
          
          //drawFeaturePoints(image, faces[0].featurePoints);
        }
      });

      //Draw the detected facial feature points on the image
      // function drawFeaturePoints(img, featurePoints) {
      //   var contxt = $('#face_video_canvas')[0].getContext('2d');

      //   var hRatio = contxt.canvas.width / img.width;
      //   var vRatio = contxt.canvas.height / img.height;
      //   var ratio = Math.min(hRatio, vRatio);

      //   contxt.strokeStyle = "#FFFFFF";
      //   for (var id in featurePoints) {
      //     contxt.beginPath();
      //     contxt.arc(featurePoints[id].x,
      //       featurePoints[id].y, 2, 0, 2 * Math.PI);
      //     contxt.stroke();

      //   }
      // }

//Affectiva code

function getDevices() {
  AgoraRTC.getDevices(function (devices) {
    for (var i = 0; i !== devices.length; ++i) {
      var device = devices[i];
      var option = document.createElement('option');
      option.value = device.deviceId;
      if (device.kind === 'audioinput') {
        option.text = device.label || 'microphone ' + (audioSelect.length + 1);
        audioSelect.appendChild(option);
      } else if (device.kind === 'videoinput') {
        option.text = device.label || 'camera ' + (videoSelect.length + 1);
        videoSelect.appendChild(option);
      } else {
        console.log('Some other kind of source/device: ', device);
      }
    }
  });
}
//audioSelect.onchange = getDevices;
//videoSelect.onchange = getDevices;
getDevices();
</script>
</body>
</html>